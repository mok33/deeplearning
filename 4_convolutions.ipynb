{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataimpact/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras \n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "#neural network \n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.05\n",
    "set_session(tf.Session(config=config))\n",
    "import numpy as np\n",
    "# import os\n",
    "# os.environ[\"THEANO_FLAGS\"] = \"device=gpu0\"\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPool1D, MaxPooling2D, Dropout, Activation, LSTM, Input, merge, Reshape, Flatten, LocallyConnected1D, Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataimpact/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ma...)`\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers, losses, utils, regularizers\n",
    "\n",
    "train_set_size = 5000\n",
    "\n",
    "input_layer = Input(shape=(28, 28, 1), name='input_image')\n",
    "\n",
    "conv_layer1 = Conv2D(32, kernel_size=(5, 5), activation='relu', strides=(1,1))(input_layer)\n",
    "conv_layer1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv_layer1)\n",
    "conv_layer2 = Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation = 'relu')(conv_layer1)\n",
    "conv_layer2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv_layer2)\n",
    "\n",
    "f_layer = Flatten()(conv_layer2)\n",
    "hidden_layer = Dense(units=1000, activation='relu')(f_layer)\n",
    "hidden_layer = Dropout(0.5)(hidden_layer)\n",
    "output = Dense(units=10, activation='softmax', name='main_output')(hidden_layer)\n",
    "\n",
    "model = Model(input=input_layer, output=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['categorical_accuracy'])\n",
    "\n",
    "one_hot_train_labels = utils.to_categorical(train_labels, num_classes=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 55s 922us/step - loss: 0.4169 - categorical_accuracy: 0.8780\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 53s 885us/step - loss: 0.3621 - categorical_accuracy: 0.8920\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.3306 - categorical_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.3088 - categorical_accuracy: 0.9068\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2914 - categorical_accuracy: 0.9110\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 77s 1ms/step - loss: 0.2765 - categorical_accuracy: 0.9157\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.2633 - categorical_accuracy: 0.9199\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.2511 - categorical_accuracy: 0.9230\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.2403 - categorical_accuracy: 0.9264\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.2295 - categorical_accuracy: 0.9299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f327c835e80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 60000\n",
    "model.fit(train_dataset[:train_size, :, :], train_labels[:train_size], epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 304us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14178905156180263, 0.9565]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted D, actual D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f323e3addd8>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "classes = \"ABCDEFGHIJ\"\n",
    "rd = np.random.randint(len(test_dataset))\n",
    "print(\"predicted {}, actual {}\".format(classes[model.predict(test_dataset[rd, :, :].reshape(1,28,28,1)).argmax()], classes[test_labels[rd].argmax()]))\n",
    "\n",
    "plt.imshow(test_dataset[rd, :, :].reshape(28,28))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
